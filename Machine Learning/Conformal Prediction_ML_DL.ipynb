{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca35fcbe-f5fc-46de-91c6-ac27aea2d217",
   "metadata": {},
   "outputs": [],
   "source": [
    "### A. CONFORMAL PREDICTION TESTING WITH OPTIMIZED DL MODELS##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "e27c2c54-06c4-46dd-b261-16fc11c263b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from scikeras.wrappers import KerasClassifier  \n",
    "from mapie.classification import MapieClassifier\n",
    "from sklearn.utils.validation import check_is_fitted\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cb3ac86-31c4-4980-905f-32b50d723301",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.05 # Conformal Confidence Prediction threshold\n",
    "score_thresh = 0.9 # Minimum confidence threshold for valid predictions\n",
    "model_names = [ \"OneLow\", \"TwoTypes\", \"ThreeTypes\", \"FourTypes\", \"OneHigh\", \"TwoHigh\", \"TwoLow\"]\n",
    "calib_data_path = \"./Data_Splits\"\n",
    "mdl_path = \"./MDL\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "bd1b5bfe-be09-40c7-96c6-0b650d4ad15c",
   "metadata": {},
   "outputs": [],
   "source": [
    "calib_data = {}\n",
    "calib_labels = {}\n",
    "\n",
    "for model_name in model_names:\n",
    "    x_calib_file = os.path.join(calib_data_path, f\"x_calib_{model_name}.npy\")\n",
    "    y_calib_file = os.path.join(calib_data_path, f\"y_calib_{model_name}.npy\")\n",
    "\n",
    "    if os.path.exists(x_calib_file) and os.path.exists(y_calib_file):\n",
    "        calib_data[model_name] = np.load(x_calib_file, allow_pickle=True)\n",
    "        calib_labels[model_name] = np.load(y_calib_file, allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "1990b758-136b-4d34-a0a6-685f08e1c84f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = {}\n",
    "test_labels = {}\n",
    "\n",
    "for model_name in model_names:\n",
    "    x_test_file = os.path.join(calib_data_path, f\"x_test_{model_name}.npy\")\n",
    "    y_test_file = os.path.join(calib_data_path, f\"y_test_{model_name}.npy\")\n",
    "\n",
    "    if os.path.exists(x_test_file) and os.path.exists(y_test_file):\n",
    "        test_data[model_name] = np.load(x_test_file, allow_pickle=True)\n",
    "        test_labels[model_name] = np.load(y_test_file, allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1413d58-04aa-4907-a861-d1fd57a061d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from mapie.classification import MapieClassifier\n",
    "from scikeras.wrappers import KerasClassifier  #  SciKeras Wrapper for TensorFlow Model\n",
    "\n",
    "# Ensure eager execution is enabled\n",
    "tf.compat.v1.experimental.output_all_intermediates(True)\n",
    "tf.config.run_functions_eagerly(True)\n",
    "\n",
    "models = {}\n",
    "\n",
    "for model_name in model_names:\n",
    "    model_path = os.path.join(mdl_path, f\"{model_name}_best.h5\")\n",
    "\n",
    "    if os.path.exists(model_path):\n",
    "        #  Ensure calibration data is in NumPy format\n",
    "        X_calib = np.array(calib_data[model_name])\n",
    "        y_calib = np.array(calib_labels[model_name])\n",
    "\n",
    "        #  Define a function that loads and compiles the model\n",
    "        def create_model():\n",
    "            model = tf.keras.models.load_model(model_path)  # Load model from file\n",
    "            model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),  \n",
    "                          loss='sparse_categorical_crossentropy', \n",
    "                          metrics=['accuracy'])\n",
    "            return model\n",
    "\n",
    "        # Wrap model inside KerasClassifier\n",
    "        keras_clf = KerasClassifier(model=create_model, epochs=1, batch_size=32, verbose=1)\n",
    "\n",
    "        # Fit model before MAPIE (SciKeras expects a trainable model)\n",
    "        keras_clf.fit(X_calib, y_calib)\n",
    "\n",
    "        # Use MAPIE for uncertainty estimation\n",
    "        mapie_clf = MapieClassifier(estimator=keras_clf, method=\"score\", cv=\"prefit\")\n",
    "        mapie_clf.fit(X_calib, y_calib)\n",
    "\n",
    "        #  Store trained model\n",
    "        models[model_name] = mapie_clf\n",
    "\n",
    "print(\" Models successfully fitted.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65fc90eb-d516-4cfb-8f13-5f143f33f786",
   "metadata": {},
   "outputs": [],
   "source": [
    "psets = {}\n",
    "\n",
    "for model_name in model_names:\n",
    "    if model_name in models and model_name in test_data:\n",
    "        print(f\"Processing model: {model_name}\")\n",
    "        mapie_clf = models[model_name]\n",
    "        try:\n",
    "            check_is_fitted(mapie_clf)\n",
    "            _, y_psets = mapie_clf.predict(test_data[model_name], alpha=[alpha])  # Generate prediction sets\n",
    "            psets[model_name] = y_psets\n",
    "            print(f\"Shape of prediction set for {model_name}: {y_psets.shape}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Skipping {model_name} due to prediction error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b85ac2c8-a9eb-4da4-b8ce-17e18058b4c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_tags = 0\n",
    "total_steps = 0\n",
    "expected_set_size = 0\n",
    "num_cards = len(set(np.concatenate(list(test_labels.values()))))\n",
    "\n",
    "start_index = model_names.index(\"OneLow\")\n",
    "ordered_model_names = model_names[start_index:] + model_names[:start_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fba8f65-94de-4ce8-959a-25d18415f07a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for model_name in ordered_model_names:\n",
    "    if model_name not in test_labels or model_name not in psets:\n",
    "        continue\n",
    "\n",
    "    y_test = test_labels[model_name]\n",
    "    y_psets = psets[model_name]\n",
    "\n",
    "    for test_num in range(len(y_test)):\n",
    "        tag_scores = np.zeros(num_cards)\n",
    "        correct_tag = int(y_test[test_num])\n",
    "\n",
    "        tag_guess = None\n",
    "        steps = 0\n",
    "\n",
    "        for y_psets in psets.values():\n",
    "            tags = [j for j in range(num_cards) if y_psets[test_num][j] == True]\n",
    "            expected_set_size += len(tags)\n",
    "            steps += 1\n",
    "\n",
    "            for tag in tags:\n",
    "                tag_scores[tag] += tags.count(tag) / len(tags)\n",
    "\n",
    "            if max(tag_scores) > score_thresh:\n",
    "                is_unique_max = np.count_nonzero(tag_scores == max(tag_scores)) == 1\n",
    "                if is_unique_max:\n",
    "                    tag_guess = np.argmax(tag_scores)\n",
    "                    break\n",
    "            else:\n",
    "                # If no prediction meets the threshold, choose the class with the highest probability\n",
    "                tag_guess = np.argmax(tag_scores)\n",
    "\n",
    "        total_steps += steps\n",
    "        if tag_guess == correct_tag:\n",
    "            correct_tags += 1\n",
    "\n",
    "total_tests = sum(len(y) for y in test_labels.values())\n",
    "accuracy = correct_tags / total_tests if total_tests > 0 else 0\n",
    "avg_steps = total_steps / total_tests if total_tests > 0 else 0\n",
    "avg_set_size = expected_set_size / total_tests if total_tests > 0 else 0\n",
    "\n",
    "print(f\"Adaptive Identification Accuracy (A): {accuracy:.2%}\")\n",
    "print(f\"Average Steps Taken (E[step]): {avg_steps:.2f}\")\n",
    "print(f\"Average Prediction Set Size (E[|S|]): {avg_set_size:.2f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cfe1db0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "244b6d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#####  B. Conformal   Prediction ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "215a87fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from mapie.classification import MapieClassifier\n",
    "from joblib import dump, load\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d412e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_one_high = np.load(\"OneHigh_.npy\", allow_pickle=True)\n",
    "data_one_low = np.load(\"OneLow_.npy\", allow_pickle=True)\n",
    "data_two_high = np.load(\"TwoHigh_.npy\", allow_pickle=True)\n",
    "data_two_low = np.load(\"TwoLow_.npy\", allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c42f4ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize datasets\n",
    "normalization_point = 0.5\n",
    "def normalize_data(data):\n",
    "    for i in range(52):\n",
    "        data_abs = np.abs(data[:, :, i])\n",
    "        min_point = np.min(data_abs)\n",
    "        diff = min_point - normalization_point\n",
    "        data[:, :, i] = np.abs(data[:, :, i]) - diff\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfee731b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize each dataset individually\n",
    "data_one_high = normalize_data(data_one_high)\n",
    "data_one_low = normalize_data(data_one_low)\n",
    "data_two_high = normalize_data(data_two_high)\n",
    "data_two_low = normalize_data(data_two_low)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e45802be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate datasets for training\n",
    "dataset = np.concatenate((data_one_high, data_one_low, data_two_high, data_two_low), axis=1)\n",
    "X_combined = np.empty((dataset.shape[0] * dataset.shape[2], dataset.shape[1]), dtype=np.complex_)\n",
    "labels = np.empty((dataset.shape[0] * dataset.shape[2]))\n",
    "\n",
    "for card in range(dataset.shape[2]):\n",
    "    responses = dataset[:, :, card]\n",
    "    start_idx = card * dataset.shape[0]\n",
    "    end_idx = start_idx + dataset.shape[0]\n",
    "    X_combined[start_idx:end_idx, :] = responses\n",
    "    labels[start_idx:end_idx] = card\n",
    "\n",
    "# Convert to absolute values for training\n",
    "dataset = np.abs(X_combined)\n",
    "\n",
    "\n",
    "x_train, x_temp, y_train, y_temp = train_test_split(dataset, labels, test_size=0.3, random_state=42)\n",
    "\n",
    "\n",
    "x_test, x_calib, y_test, y_calib = train_test_split(x_temp, y_temp, test_size=0.2, random_state=42)\n",
    "\n",
    "# Save train, test, and calibration sets\n",
    "os.makedirs('./Testing', exist_ok=True)\n",
    "np.save('./Testing/x_train', x_train)\n",
    "np.save('./Testing/y_train', y_train)\n",
    "np.save('./Testing/x_test', x_test)\n",
    "np.save('./Testing/y_test', y_test)\n",
    "np.save('./Testing/x_calib', x_calib)\n",
    "np.save('./Testing/y_calib', y_calib)\n",
    "\n",
    "# Define lengths for sub-carrier response types\n",
    "one_high_len = 910\n",
    "one_low_len = 3624\n",
    "two_high_len = 900\n",
    "two_low_len = 3599\n",
    "\n",
    "# Model training function with resume functionality\n",
    "def train_and_save_model(features, labels, model_name):\n",
    "    model_path = f'./Models/{model_name}.joblib'\n",
    "    os.makedirs('./Models', exist_ok=True)\n",
    "    \n",
    "    # Check if model already exists\n",
    "    if os.path.exists(model_path):\n",
    "        print(f\"{model_name} model already exists. Loading saved model.\")\n",
    "        mapie_clf = load(model_path)\n",
    "    else:\n",
    "        print(f\"Training {model_name}...\")\n",
    "        base_clf = RandomForestClassifier()\n",
    "        mapie_clf = MapieClassifier(estimator=base_clf, method=\"score\")\n",
    "        mapie_clf.fit(features, labels)\n",
    "        dump(mapie_clf, model_path)\n",
    "        print(f\"{model_name} model saved at {model_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ae897dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conformal Prediction using calibration set\n",
    "num_cards = 52\n",
    "score_thresh = 0.8\n",
    "alpha = 0.15\n",
    "expected_set_size = 0\n",
    "total_steps = 0\n",
    "\n",
    "# Define model test data combinations\n",
    "model_names = [\"OneLow\", \"TwoTypes\", \"ThreeTypes\", \"FourTypes\", \"OneHigh\", \"TwoHigh\", \"TwoLow\"]\n",
    "test_combinations = [\n",
    "    x_test[:, :one_low_len + one_high_len],  \n",
    "    x_test[:, :two_high_len + one_high_len + one_low_len],  \n",
    "    x_test,  \n",
    "    x_test[:, :one_high_len],  \n",
    "    x_test[:, one_high_len:one_high_len + one_low_len],  \n",
    "    x_test[:, one_high_len + one_low_len:one_high_len + one_low_len + two_high_len],  \n",
    "    x_test[:, one_high_len + one_low_len + two_high_len:]  \n",
    "]\n",
    "\n",
    "# Run predictions for each model\n",
    "psets = []\n",
    "for i, model_name in enumerate(model_names):\n",
    "    model_path = f'./Models/{model_name}.joblib'\n",
    "    if os.path.exists(model_path):\n",
    "        mapie_clf = load(model_path)\n",
    "        _, y_psets = mapie_clf.predict(test_combinations[i], alpha=alpha)\n",
    "        psets.append(y_psets)\n",
    "\n",
    "# Evaluate Conformal Prediction accuracy\n",
    "correct_tags = 0\n",
    "for test_num in range(len(y_test)):\n",
    "    tag_scores = np.zeros(num_cards)\n",
    "    correct_tag = int(y_test[test_num])\n",
    "\n",
    "    tag_guess = None\n",
    "    steps = 0\n",
    "    \n",
    "    for y_psets in psets:\n",
    "        tags = [j for j in range(num_cards) if y_psets[test_num][j] == True]\n",
    "        expected_set_size += len(tags)\n",
    "        steps += 1\n",
    "        \n",
    "        for tag in tags:\n",
    "            tag_scores[tag] += tags.count(tag) / len(tags)\n",
    "        if max(tag_scores) > score_thresh:\n",
    "                is_unique_max = np.count_nonzero(tag_scores == max(tag_scores)) == 1\n",
    "                if is_unique_max:\n",
    "                    tag_guess = np.argmax(tag_scores)\n",
    "                    break\n",
    "\n",
    "                else:\n",
    "                # If no prediction meets the threshold, choose the class with the highest probability\n",
    "                 tag_guess = np.argmax(tag_scores)\n",
    "\n",
    "        total_steps += steps\n",
    "        if tag_guess == correct_tag:\n",
    "            correct_tags += 1\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy = (correct_tags / len(y_test)) * 100\n",
    "expected_set_size /= len(y_test)\n",
    "expected_steps = total_steps / len(y_test)\n",
    "\n",
    "# Print results\n",
    "print(f\"Adaptive Identification Accuracy (A): {accuracy:.2%}\")\n",
    "print(f\"Average Steps Taken (E[step]): {avg_steps:.2f}\")\n",
    "print(f\"Average Prediction Set Size (E[|S|]): {avg_set_size:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow GPU 2.15 (py310)",
   "language": "python",
   "name": "tensorflow-gpu-2.15-py310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
